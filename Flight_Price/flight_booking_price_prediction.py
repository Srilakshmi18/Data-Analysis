# -*- coding: utf-8 -*-
"""Flight Booking Price Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Zh4u8LZjMf2oNB9_sERClxo2E1gaAcGk
"""

#Import the libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")

"""Load The Data"""

df=pd.read_csv("/content/Flight_Booking.csv")

"""EDA"""

df.shape

df.info()

df.head()

df.drop(["Unnamed: 0","flight"],axis=1,inplace=True)

df

df.isnull().sum()

df.duplicated().sum()

df.drop_duplicates(inplace=True)

df.shape

df.info()

df.describe()

"""DATA VISUALIZATION"""

plt.figure(figsize=(10,5))
sns.barplot(data=df,x="airline",y="price",hue="class")
plt.show()

plt.figure(figsize=(10,5))
sns.lineplot(data=df,x="airline",y="price")
plt.show()

plt.figure(figsize=(10,5))
sns.barplot(data=df,x="airline",y="price")
plt.show()

plt.figure(figsize=(10,5))
sns.barplot(data=df,x="class",y="price")
plt.show()

plt.figure(figsize=(10,5))
sns.barplot(data=df,x="days_left",y="price",hue="class")
plt.show()

plt.figure(figsize=(10,5))
sns.barplot(data=df,x="airline",y="price",hue="departure_time")
plt.show()

fig,ax=plt.subplots(1,2,figsize=(20,6))
sns.lineplot(data=df,x="days_left",y="price",hue="source_city",ax=ax[0])
sns.lineplot(data=df,x="days_left",y="price",hue="destination_city",ax=ax[1])
plt.show()

plt.figure(figsize=(15,23))

plt.subplot(4,2,1)
sns.countplot(data=df,x="airline")
plt.title("Frequency of Airline")

plt.subplot(4,2,2)
sns.countplot(data=df,x="source_city")
plt.title("Frequency of Source City")

plt.subplot(4,2,3)
sns.countplot(data=df,x="destination_city")
plt.title("Frequency of Destination City")

plt.subplot(4,2,4)
sns.countplot(data=df,x="class")
plt.title("Frequency of Class")

plt.subplot(4,2,5)
sns.countplot(data=df,x="stops")
plt.title("Frequency of Stops")

plt.subplot(4,2,6)
sns.countplot(data=df,x="departure_time")
plt.title("Frequency of Departure Time")

plt.subplot(4,2,7)
sns.countplot(data=df,x="arrival_time")
plt.title("Frequency of Arrival Time")

plt.show()

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()

df.columns

for col in df.columns:
    if df[col].dtype=="object":
        df[col]=le.fit_transform(df[col])

df.info()

df.head()

plt.figure(figsize=(10,5))
sns.heatmap(df.corr(),annot=True,cmap="coolwarm")
plt.show()

from statsmodels.stats.outliers_influence import  variance_inflation_factor

col_list=[]
for i in df.columns:
    if (df[i].dtype!="object") & (i!="price"):
        col_list.append(i)

X=df[col_list]
vif_data=pd.DataFrame()
vif_data["features"]=X.columns
vif_data["VIF"]=[variance_inflation_factor(X.values,i) for i in range(len(X.columns))]
vif_data

from sklearn.preprocessing  import StandardScaler

sc=StandardScaler()

x=sc.fit_transform(X)

x

x=pd.DataFrame(x,columns=col_list)

x

y=df["price"]

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=67)

from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor

"""LINEAR REGRESSION"""

lr=LinearRegression()

lr.fit(x_train,y_train)

y_pred=lr.predict(x_test)
y_pred

y_test

difference=pd.DataFrame(np.c_[y_test,y_pred],columns=["Actual_Value","Predicted_Value"])
difference

# Evaluation of the model
from sklearn.metrics import *

lr_score=r2_score(y_test,y_pred)
lr_score

mse=mean_squared_error(y_test,y_pred)
mse

rmse=np.sqrt(mean_squared_error(y_test,y_pred))
rmse

mae=mean_absolute_error(y_test,y_pred)
mae

mape=mean_absolute_percentage_error(y_test,y_pred)
mape

sns.distplot(y_test,label="Actual")
sns.distplot(y_pred,label="Predicted")
plt.legend()

"""DECISION TREE REGRESSOR

"""

dt=DecisionTreeRegressor()

dt.fit(x_train,y_train)

dt_pred=dt.predict(x_test)
dt_pred

y_test

diff=pd.DataFrame(np.c_[y_test,dt_pred],columns=["Actual_Value","Predicted_Value"])
diff

#Evaluation of the model
dt_score=r2_score(y_test,dt_pred)
dt_score

dt_mse=mean_squared_error(y_test,dt_pred)
dt_mse

dt_rmse=np.sqrt(mean_squared_error(y_test,dt_pred))
dt_rmse

dt_mae=mean_absolute_error(y_test,dt_pred)
dt_mae

dt_mape=mean_absolute_percentage_error(y_test,dt_pred)
dt_mape

sns.distplot(y_test,label="Actual")
sns.distplot(dt_pred,label="Predicted")
plt.legend()

"""RANDOM TREE REGRESSOR"""

rf_model=RandomForestRegressor()

rf_model.fit(x_train,y_train)

rf_pred=rf_model.predict(x_test)
rf_pred

y_test

diff1=pd.DataFrame(np.c_[y_test,rf_pred],columns=["Actual_Value","Predicted_Value"])
diff1

#Evaluation of Model
rf_score=r2_score(y_test,rf_pred)
rf_score

rf_mse=mean_squared_error(y_test,rf_pred)
rf_mse

rf_rmse=np.sqrt(mean_squared_error(y_test,rf_pred))
rf_rmse

rf_mae=mean_absolute_error(y_test,rf_pred)
rf_mae

rf_mape=mean_absolute_percentage_error(y_test,rf_pred)
rf_mape

# Conclusion:
print("Linear Regression- r2_score=",lr_score,"and rmse=",rmse,"and mape=",mape)
print("DT regressor-  r2_score=",dt_score,"and rmse=",dt_rmse,"and mape=",dt_mape)
print("RF regressor-  r2_score=",rf_score,"and rmse=",rf_rmse,"and mape=",rf_mape)

#Higher the r2_score, lower the rmse and mape-- better the model
#HENCE, THE BEST MODEL IS RONDOM TREE REGRESSOR

sns.distplot(y_test,label="Actual")
sns.distplot(rf_pred,label="Predicted")
plt.legend()